{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import contractions\n",
    "import unidecode\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import treebank_chunk \n",
    "from nltk.chunk import RegexpParser \n",
    "\n",
    "text = \"Hey there! ðŸ˜ƒ I can't believe it's already 2024. Did you see John's new blog post? Check it out at https://example.com/blog! Also, email me at john.doe@example.com. He mentioned something about stemming and lemmatizationâ€”interesting stuff. BTW, I'll be attending the AI conference in N.Y.C. next month!! #Excited #AI ðŸ˜Š Let's catch up soon. Cheers, John\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_words = []    \n",
    "for word in text.split():\n",
    "  # using contractions.fix to expand the shortened words\n",
    "  expanded_words.append(contractions.fix(word))   \n",
    "   \n",
    "expanded_text = ' '.join(expanded_words)\n",
    "text = expanded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original String: Hey there! ðŸ˜ƒ I can't believe it's already 2024. Did you see John's new blog post? Check it out at https://example.com/blog! Also, email me at john.doe@example.com. He mentioned something about stemming and lemmatizationâ€”interesting stuff. BTW, I'll be attending the AI conference in N.Y.C. next month!! #Excited #AI ðŸ˜Š Let's catch up soon. Cheers, John\n",
      "\n",
      "New String: Hey there!  I can't believe it's already 2024. Did you see John's new blog post? Check it out at https://example.com/blog! Also, email me at john.doe@example.com. He mentioned something about stemming and lemmatization--interesting stuff. BTW, I'll be attending the AI conference in N.Y.C. next month!! #Excited #AI  Let's catch up soon. Cheers, John\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# display original string\n",
    "print('\\nOriginal String:', text)\n",
    "# remove ascents\n",
    "text = unidecode.unidecode(text)\n",
    " \n",
    "# display new string\n",
    "print('\\nNew String:', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey there!  i can't believe it's already 2024. did you see john's new blog post? check it out at https://example.com/blog! also, email me at john.doe@example.com. he mentioned something about stemming and lemmatization--interesting stuff. btw, i'll be attending the ai conference in n.y.c. next month!! #excited #ai  let's catch up soon. cheers, john\n",
      "HEY THERE!  I CAN'T BELIEVE IT'S ALREADY 2024. DID YOU SEE JOHN'S NEW BLOG POST? CHECK IT OUT AT HTTPS://EXAMPLE.COM/BLOG! ALSO, EMAIL ME AT JOHN.DOE@EXAMPLE.COM. HE MENTIONED SOMETHING ABOUT STEMMING AND LEMMATIZATION--INTERESTING STUFF. BTW, I'LL BE ATTENDING THE AI CONFERENCE IN N.Y.C. NEXT MONTH!! #EXCITED #AI  LET'S CATCH UP SOON. CHEERS, JOHN\n"
     ]
    }
   ],
   "source": [
    "print(text.lower())\n",
    "print(text.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there!  I can't believe it's already 2024. Did you see John's new blog post? Check it out at  Also, email me at john.doe@example.com. He mentioned something about stemming and lemmatization--interesting stuff. BTW, I'll be attending the AI conference in N.Y.C. next month!! #Excited #AI  Let's catch up soon. Cheers, John\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = re.sub(r'http\\S+', '', text)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there!  I can't believe it's already 2024. Did you see John's new blog post? Check it out at  Also, email me at john.doe@example.com. He mentioned something about stemming and lemmatization--interesting stuff. BTW, I'll be attending the AI conference in N.Y.C. next month!! #Excited #AI  Let's catch up soon. Cheers, John\n",
      "CountVectorizer Results:\n",
      "    2024  about  ai  already  also  and  at  attending  be  believe  ...  post   \n",
      "0     1      1   2        1     1    1   2          1   1        1  ...     1  \\\n",
      "\n",
      "   see  something  soon  stemming  stuff  the  there  up  you  \n",
      "0    1          1     1         1      1    1      1   1    1  \n",
      "\n",
      "[1 rows x 48 columns]\n",
      "\n",
      "TfidfVectorizer Results:\n",
      "        2024     about        ai   already      also       and        at   \n",
      "0  0.124035  0.124035  0.248069  0.124035  0.124035  0.124035  0.248069  \\\n",
      "\n",
      "   attending        be   believe  ...      post       see  something   \n",
      "0   0.124035  0.124035  0.124035  ...  0.124035  0.124035   0.124035  \\\n",
      "\n",
      "       soon  stemming     stuff       the     there        up       you  \n",
      "0  0.124035  0.124035  0.124035  0.124035  0.124035  0.124035  0.124035  \n",
      "\n",
      "[1 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count vectorizer\n",
    "\n",
    "print(text)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=None)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=None)\n",
    "\n",
    "count_vectorized = count_vectorizer.fit_transform([text])\n",
    "tfidf_vectorized = tfidf_vectorizer.fit_transform([text])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "count_df = pd.DataFrame(count_vectorized.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "tfidf_df = pd.DataFrame(tfidf_vectorized.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"CountVectorizer Results:\\n\", count_df)\n",
    "print(\"\\nTfidfVectorizer Results:\\n\", tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  This is a one of the best apps acording to a b...         1\n",
       "1  This is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  This is a silly game and can be frustrating, b...         1\n",
       "4  This is a terrific game on any pad. Hrs of fun...         1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"textdata.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer Feature Names:\n",
      "['aa' 'aaa' 'aaaa' ... 'zzz' 'zzzz' 'zzzzz']\n",
      "\n",
      "Count Vectorizer Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "TF-IDF Vectorizer Feature Names:\n",
      "['aa' 'aaa' 'aaaa' ... 'zzz' 'zzzz' 'zzzzz']\n",
      "\n",
      "TF-IDF Vectorizer Matrix:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "data['cleaned_text'] = data['reviewText'].apply(preprocess_text)\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(data['cleaned_text'])\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['cleaned_text'])\n",
    "print(\"Count Vectorizer Feature Names:\")\n",
    "print(count_vectorizer.get_feature_names_out())\n",
    "print(\"\\nCount Vectorizer Matrix:\")\n",
    "print(count_matrix.toarray())\n",
    "\n",
    "print(\"\\nTF-IDF Vectorizer Feature Names:\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Vectorizer Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "                                               reviewText  Positive   \n",
      "0      This is a one of the best apps acording to a b...         1  \\\n",
      "1      This is a pretty good version of the game for ...         1   \n",
      "2      this is a really cool game. there are a bunch ...         1   \n",
      "3      This is a silly game and can be frustrating, b...         1   \n",
      "4      This is a terrific game on any pad. Hrs of fun...         1   \n",
      "...                                                  ...       ...   \n",
      "19995  this app is fricken stupid.it froze on the kin...         0   \n",
      "19996  Please add me!!!!! I need neighbors! Ginger101...         1   \n",
      "19997  love it!  this game. is awesome. wish it had m...         1   \n",
      "19998  I love love love this app on my side of fashio...         1   \n",
      "19999  This game is a rip off. Here is a list of thin...         0   \n",
      "\n",
      "                                      cleaned_reviewText  \n",
      "0      one best apps acording bunch people agree bomb...  \n",
      "1      pretty good version game free lot different le...  \n",
      "2      really cool game bunch level find golden egg s...  \n",
      "3      silly game frustrating lot fun definitely reco...  \n",
      "4      terrific game pad hr fun grandkids love great ...  \n",
      "...                                                  ...  \n",
      "19995  app fricken stupidit froze kindle wont allow p...  \n",
      "19996  please add need neighbor ginger thanks bunch a...  \n",
      "19997  love game awesome wish free stuff house didnt ...  \n",
      "19998  love love love app side fashion story fight wo...  \n",
      "19999  game rip list thing make betterbull first need...  \n",
      "\n",
      "[20000 rows x 3 columns]\n",
      "\n",
      "CountVectorizer Results:\n",
      "        aa  aaa  aaaa  aaaaaaa  aaaaaaaaammmazinng  aaaah   \n",
      "0       0    0     0        0                   0      0  \\\n",
      "1       0    0     0        0                   0      0   \n",
      "2       0    0     0        0                   0      0   \n",
      "3       0    0     0        0                   0      0   \n",
      "4       0    0     0        0                   0      0   \n",
      "...    ..  ...   ...      ...                 ...    ...   \n",
      "19995   0    0     0        0                   0      0   \n",
      "19996   0    0     0        0                   0      0   \n",
      "19997   0    0     0        0                   0      0   \n",
      "19998   0    0     0        0                   0      0   \n",
      "19999   0    0     0        0                   0      0   \n",
      "\n",
      "       aaaawwwwssssoooommmmeeee  aaarp  aaawwwweeesssooommmeee  aac  ...   \n",
      "0                             0      0                       0    0  ...  \\\n",
      "1                             0      0                       0    0  ...   \n",
      "2                             0      0                       0    0  ...   \n",
      "3                             0      0                       0    0  ...   \n",
      "4                             0      0                       0    0  ...   \n",
      "...                         ...    ...                     ...  ...  ...   \n",
      "19995                         0      0                       0    0  ...   \n",
      "19996                         0      0                       0    0  ...   \n",
      "19997                         0      0                       0    0  ...   \n",
      "19998                         0      0                       0    0  ...   \n",
      "19999                         0      0                       0    0  ...   \n",
      "\n",
      "       zoom  zoomed  zooming  zpg  zto  zumocast  zz  zzz  zzzz  zzzzz  \n",
      "0         0       0        0    0    0         0   0    0     0      0  \n",
      "1         0       0        0    0    0         0   0    0     0      0  \n",
      "2         0       0        0    0    0         0   0    0     0      0  \n",
      "3         0       0        0    0    0         0   0    0     0      0  \n",
      "4         0       0        0    0    0         0   0    0     0      0  \n",
      "...     ...     ...      ...  ...  ...       ...  ..  ...   ...    ...  \n",
      "19995     0       0        0    0    0         0   0    0     0      0  \n",
      "19996     0       0        0    0    0         0   0    0     0      0  \n",
      "19997     0       0        0    0    0         0   0    0     0      0  \n",
      "19998     0       0        0    0    0         0   0    0     0      0  \n",
      "19999     0       0        0    0    0         0   0    0     0      0  \n",
      "\n",
      "[20000 rows x 21077 columns]\n",
      "\n",
      "TfidfVectorizer Results:\n",
      "         aa  aaa  aaaa  aaaaaaa  aaaaaaaaammmazinng  aaaah   \n",
      "0      0.0  0.0   0.0      0.0                 0.0    0.0  \\\n",
      "1      0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "2      0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "3      0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "4      0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "...    ...  ...   ...      ...                 ...    ...   \n",
      "19995  0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "19996  0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "19997  0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "19998  0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "19999  0.0  0.0   0.0      0.0                 0.0    0.0   \n",
      "\n",
      "       aaaawwwwssssoooommmmeeee  aaarp  aaawwwweeesssooommmeee  aac  ...   \n",
      "0                           0.0    0.0                     0.0  0.0  ...  \\\n",
      "1                           0.0    0.0                     0.0  0.0  ...   \n",
      "2                           0.0    0.0                     0.0  0.0  ...   \n",
      "3                           0.0    0.0                     0.0  0.0  ...   \n",
      "4                           0.0    0.0                     0.0  0.0  ...   \n",
      "...                         ...    ...                     ...  ...  ...   \n",
      "19995                       0.0    0.0                     0.0  0.0  ...   \n",
      "19996                       0.0    0.0                     0.0  0.0  ...   \n",
      "19997                       0.0    0.0                     0.0  0.0  ...   \n",
      "19998                       0.0    0.0                     0.0  0.0  ...   \n",
      "19999                       0.0    0.0                     0.0  0.0  ...   \n",
      "\n",
      "       zoom  zoomed  zooming  zpg  zto  zumocast   zz  zzz  zzzz  zzzzz  \n",
      "0       0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "1       0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "2       0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "3       0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "4       0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "...     ...     ...      ...  ...  ...       ...  ...  ...   ...    ...  \n",
      "19995   0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "19996   0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "19997   0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "19998   0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "19999   0.0     0.0      0.0  0.0  0.0       0.0  0.0  0.0   0.0    0.0  \n",
      "\n",
      "[20000 rows x 21077 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
